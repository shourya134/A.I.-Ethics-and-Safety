# Ethics Guidelines

## Research Purpose

This framework is designed exclusively for **defensive AI safety research**. The goal is to understand and mitigate jailbreak attacks, not to facilitate them.

## Acceptable Use

✅ **Allowed:**
- Studying attack patterns for defensive purposes
- Developing detection and mitigation systems
- Academic research on AI safety
- Building robust AI systems
- Educational demonstrations in controlled environments

❌ **Prohibited:**
- Using attack methods to harm AI systems
- Bypassing AI safety measures for malicious purposes
- Generating harmful content
- Teaching others to exploit AI systems
- Any use that violates platform terms of service

## Data Handling

- **Secure Storage**: All harmful examples must be stored securely
- **Access Control**: Limit access to authorized researchers only
- **Data Minimization**: Use only necessary data for research
- **Cleanup**: Delete generated harmful content after research completion

## IRB Approval

Consider seeking Institutional Review Board (IRB) approval for:
- Human subject evaluation studies
- Large-scale data collection
- Public deployment of tools
- Research involving sensitive content

## Responsible Disclosure

If you discover new vulnerabilities:
1. Document findings responsibly
2. Contact relevant AI companies privately
3. Allow reasonable time for fixes
4. Follow coordinated disclosure practices

## Contribution Guidelines

All contributors must:
- Agree to these ethics guidelines
- Focus on defensive applications
- Avoid publishing exploit code
- Consider societal impact of research

## Contact

For ethics concerns or questions, contact: [your-ethics-email@institution.edu]