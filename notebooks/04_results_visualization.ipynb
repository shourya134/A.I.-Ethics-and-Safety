{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# üìä Results Visualization Demo\n",
    "\n",
    "This notebook demonstrates how to use the visualization framework to analyze jailbreak detection results.\n",
    "\n",
    "## Overview\n",
    "- Load and examine evaluation results\n",
    "- Create comprehensive dashboards\n",
    "- Generate metric comparisons\n",
    "- Analyze performance trade-offs\n",
    "- Export visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Import visualization modules\n",
    "from src.visualization import ResultsDashboard, MetricsVisualizer, ComparisonCharts\n",
    "\n",
    "# Jupyter display settings\n",
    "from IPython.display import display, HTML\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "\n",
    "print(\"üõ°Ô∏è AI Safety Jailbreak Research - Visualization Demo\")\n",
    "print(\"üìÖ Notebook initialized:\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## üìä Sample Results Data\n",
    "\n",
    "For demonstration, we'll create sample evaluation results. In practice, you would load these from your evaluation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample evaluation results\n",
    "sample_results = {\n",
    "    \"prompt_level_detector\": {\n",
    "        \"asr\": 0.15,  # Attack Success Rate (lower is better)\n",
    "        \"fpr\": 0.08,  # False Positive Rate (lower is better)\n",
    "        \"precision\": 0.89,\n",
    "        \"recall\": 0.85,\n",
    "        \"f1\": 0.87,\n",
    "        \"accuracy\": 0.88,\n",
    "        \"latency\": 45.2,  # ms\n",
    "        \"confusion_matrix\": [[450, 40], [75, 435]],\n",
    "        \"roc_curve\": {\n",
    "            \"fpr\": [0.0, 0.02, 0.08, 0.15, 0.25, 1.0],\n",
    "            \"tpr\": [0.0, 0.60, 0.85, 0.92, 0.96, 1.0],\n",
    "            \"auc\": 0.91\n",
    "        }\n",
    "    },\n",
    "    \"multi_turn_detector\": {\n",
    "        \"asr\": 0.22,\n",
    "        \"fpr\": 0.12,\n",
    "        \"precision\": 0.82,\n",
    "        \"recall\": 0.78,\n",
    "        \"f1\": 0.80,\n",
    "        \"accuracy\": 0.83,\n",
    "        \"latency\": 78.5,\n",
    "        \"confusion_matrix\": [[440, 60], [110, 390]],\n",
    "        \"roc_curve\": {\n",
    "            \"fpr\": [0.0, 0.05, 0.12, 0.25, 0.40, 1.0],\n",
    "            \"tpr\": [0.0, 0.55, 0.78, 0.88, 0.94, 1.0],\n",
    "            \"auc\": 0.86\n",
    "        }\n",
    "    },\n",
    "    \"token_level_detector\": {\n",
    "        \"asr\": 0.10,\n",
    "        \"fpr\": 0.05,\n",
    "        \"precision\": 0.93,\n",
    "        \"recall\": 0.90,\n",
    "        \"f1\": 0.91,\n",
    "        \"accuracy\": 0.92,\n",
    "        \"latency\": 120.3,\n",
    "        \"confusion_matrix\": [[475, 25], [50, 450]],\n",
    "        \"roc_curve\": {\n",
    "            \"fpr\": [0.0, 0.01, 0.05, 0.10, 0.20, 1.0],\n",
    "            \"tpr\": [0.0, 0.70, 0.90, 0.95, 0.98, 1.0],\n",
    "            \"auc\": 0.95\n",
    "        }\n",
    "    },\n",
    "    \"indirect_injection_detector\": {\n",
    "        \"asr\": 0.18,\n",
    "        \"fpr\": 0.10,\n",
    "        \"precision\": 0.85,\n",
    "        \"recall\": 0.82,\n",
    "        \"f1\": 0.83,\n",
    "        \"accuracy\": 0.86,\n",
    "        \"latency\": 32.1,\n",
    "        \"confusion_matrix\": [[450, 50], [90, 410]],\n",
    "        \"roc_curve\": {\n",
    "            \"fpr\": [0.0, 0.03, 0.10, 0.20, 0.35, 1.0],\n",
    "            \"tpr\": [0.0, 0.58, 0.82, 0.90, 0.95, 1.0],\n",
    "            \"auc\": 0.89\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üìä Sample results loaded for\", len(sample_results), \"detectors:\")\n",
    "for detector, metrics in sample_results.items():\n",
    "    print(f\"  üîç {detector}: F1={metrics['f1']:.3f}, ASR={metrics['asr']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## üéØ Performance Summary Table\n",
    "\n",
    "Let's start with a quick overview of all detector performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance summary\n",
    "metrics_viz = MetricsVisualizer()\n",
    "summary_df = metrics_viz.create_performance_summary_table(sample_results)\n",
    "\n",
    "# Display with styling\n",
    "def style_performance_table(df):\n",
    "    def color_grade(val):\n",
    "        if 'A+' in val:\n",
    "            return 'background-color: #d4edda; color: #155724'\n",
    "        elif 'A' in val:\n",
    "            return 'background-color: #cce5ff; color: #004085'\n",
    "        elif 'B' in val:\n",
    "            return 'background-color: #fff3cd; color: #856404'\n",
    "        elif 'C' in val:\n",
    "            return 'background-color: #f8d7da; color: #721c24'\n",
    "        else:\n",
    "            return 'background-color: #f8d7da; color: #721c24'\n",
    "    \n",
    "    return df.style.applymap(color_grade, subset=['Grade'])\n",
    "\n",
    "styled_table = style_performance_table(summary_df)\n",
    "display(styled_table)\n",
    "\n",
    "print(\"\\nüèÜ Best performing detector:\", summary_df.loc[summary_df['F1 Score'].astype(float).idxmax(), 'Detector'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## üìà Comprehensive Dashboard\n",
    "\n",
    "Create an interactive dashboard with multiple visualizations showing detection performance from different angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dashboard\n",
    "dashboard = ResultsDashboard()\n",
    "\n",
    "# Create comprehensive overview dashboard\n",
    "fig_overview = dashboard.create_overview_dashboard(sample_results)\n",
    "fig_overview.show()\n",
    "\n",
    "print(\"üìä Interactive dashboard created! Scroll down to explore different metrics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## üéØ Detector Performance Comparison\n",
    "\n",
    "Compare detectors using different visualization styles: bar charts, radar charts, and heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize comparison charts\n",
    "comparison = ComparisonCharts()\n",
    "\n",
    "# 1. Bar chart comparison\n",
    "print(\"üìä Bar Chart Comparison\")\n",
    "fig_bar = comparison.create_detector_comparison_chart(sample_results, chart_type='bar')\n",
    "fig_bar.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Radar chart comparison\n",
    "print(\"üéØ Radar Chart Comparison\")\n",
    "fig_radar = comparison.create_detector_comparison_chart(sample_results, chart_type='radar')\n",
    "fig_radar.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Performance ranking\n",
    "print(\"üèÜ Performance Ranking\")\n",
    "fig_ranking = comparison.create_performance_ranking(sample_results, primary_metric='f1')\n",
    "fig_ranking.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Trade-off Analysis\n",
    "\n",
    "Analyze performance trade-offs between different metrics to understand detector characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trade-off analysis\n",
    "print(\"‚öñÔ∏è Performance Trade-off Analysis\")\n",
    "fig_tradeoff = comparison.create_trade_off_analysis(sample_results)\n",
    "fig_tradeoff.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## üìè Detailed Metrics Analysis\n",
    "\n",
    "Deep dive into specific performance metrics with confusion matrices and distribution analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion matrices\n",
    "print(\"üî¢ Confusion Matrices\")\n",
    "fig_cm = metrics_viz.plot_confusion_matrices(sample_results, figsize=(16, 4))\n",
    "plt.show()\n",
    "\n",
    "# Performance distribution\n",
    "print(\"\\nüìâ Performance Distribution Analysis\")\n",
    "fig_dist = metrics_viz.plot_performance_distribution(sample_results, figsize=(15, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## üé® Custom Analysis\n",
    "\n",
    "Create custom visualizations for specific analysis needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom analysis: Security vs Speed trade-off\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Extract data for custom plot\n",
    "detectors = list(sample_results.keys())\n",
    "security_scores = [1 - sample_results[det]['asr'] for det in detectors]  # Higher is more secure\n",
    "speed_scores = [1 / sample_results[det]['latency'] * 1000 for det in detectors]  # Higher is faster\n",
    "f1_scores = [sample_results[det]['f1'] for det in detectors]\n",
    "\n",
    "# Create bubble chart\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=speed_scores,\n",
    "    y=security_scores,\n",
    "    mode='markers+text',\n",
    "    text=[det.replace('_', ' ').title() for det in detectors],\n",
    "    textposition='top center',\n",
    "    marker=dict(\n",
    "        size=[f1 * 100 for f1 in f1_scores],  # Bubble size based on F1\n",
    "        color=f1_scores,\n",
    "        colorscale='RdYlBu_r',\n",
    "        showscale=True,\n",
    "        colorbar=dict(title=\"F1 Score\"),\n",
    "        sizemode='diameter',\n",
    "        sizeref=2.*max([f1 * 100 for f1 in f1_scores])/(40.**2),\n",
    "        sizemin=4\n",
    "    ),\n",
    "    hovertemplate='<b>%{text}</b><br>' +\n",
    "                  'Security Score: %{y:.3f}<br>' +\n",
    "                  'Speed Score: %{x:.3f}<br>' +\n",
    "                  'F1 Score: %{marker.color:.3f}<br>' +\n",
    "                  '<extra></extra>'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"üõ°Ô∏è Security vs Speed Trade-off Analysis<br><sub>Bubble size = F1 Score</sub>\",\n",
    "    xaxis_title=\"Speed Score (Higher = Faster)\",\n",
    "    yaxis_title=\"Security Score (Higher = More Secure)\",\n",
    "    template=\"plotly_white\",\n",
    "    height=600,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Add quadrant labels\n",
    "fig.add_annotation(x=max(speed_scores)*0.8, y=max(security_scores)*0.9, \n",
    "                  text=\"üèÜ Ideal Zone<br>(Fast & Secure)\", \n",
    "                  bgcolor=\"lightgreen\", bordercolor=\"green\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"üéØ This bubble chart shows the trade-off between security (lower ASR) and speed.\")\n",
    "print(\"üí° Larger bubbles indicate higher F1 scores. The ideal position is top-right.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## üíæ Exporting Results\n",
    "\n",
    "Save all visualizations and generate a comprehensive report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = \"../results/notebook_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save all visualizations\n",
    "print(\"üíæ Saving visualizations...\")\n",
    "\n",
    "# 1. Save dashboard\n",
    "dashboard.save_all_plots(sample_results, f\"{output_dir}/dashboard\")\n",
    "\n",
    "# 2. Save metrics plots  \n",
    "metrics_viz.save_all_metric_plots(sample_results, f\"{output_dir}/metrics\")\n",
    "\n",
    "# 3. Save comparison charts\n",
    "comparison.save_all_comparison_charts(sample_results, f\"{output_dir}/comparisons\")\n",
    "\n",
    "# 4. Save results data\n",
    "with open(f\"{output_dir}/results_data.json\", 'w') as f:\n",
    "    json.dump(sample_results, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ All visualizations saved to: {output_dir}\")\n",
    "print(\"üìÇ You can find:\")\n",
    "print(\"  üìä Interactive dashboards (HTML)\")\n",
    "print(\"  üìà Static plots (PNG)\")\n",
    "print(\"  üìã Data tables (CSV)\")\n",
    "print(\"  üìÑ Raw results (JSON)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## üöÄ Command Line Usage\n",
    "\n",
    "You can also generate these visualizations from the command line using the interactive script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show command line usage\n",
    "print(\"üñ•Ô∏è Command Line Usage Examples:\")\n",
    "print()\n",
    "print(\"# Generate all visualizations with demo data:\")\n",
    "print(\"python scripts/visualize_results.py --demo\")\n",
    "print()\n",
    "print(\"# Use your own results file:\")\n",
    "print(\"python scripts/visualize_results.py --results-file results/evaluation_results.json\")\n",
    "print()\n",
    "print(\"# Generate only specific chart types:\")\n",
    "print(\"python scripts/visualize_results.py --demo --charts dashboard metrics\")\n",
    "print()\n",
    "print(\"# Specify output directory:\")\n",
    "print(\"python scripts/visualize_results.py --demo --output-dir ./my_plots\")\n",
    "print()\n",
    "print(\"üí° The script will generate an index.html file that links to all visualizations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## üìù Summary & Next Steps\n",
    "\n",
    "This notebook demonstrated the comprehensive visualization capabilities of the AI Safety Jailbreak Research framework.\n",
    "\n",
    "### üéØ What We Covered:\n",
    "- **Performance Overview**: Summary tables and key metrics\n",
    "- **Interactive Dashboards**: Multi-panel views with various chart types\n",
    "- **Detector Comparisons**: Bar charts, radar plots, and heatmaps\n",
    "- **Trade-off Analysis**: Understanding performance relationships\n",
    "- **Custom Visualizations**: Security vs speed analysis\n",
    "- **Export Capabilities**: Save all plots and data\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "1. **Run Real Evaluations**: Use your actual detector implementations\n",
    "2. **Customize Metrics**: Add domain-specific performance measures\n",
    "3. **Time Series Analysis**: Track performance evolution over time\n",
    "4. **A/B Testing**: Compare different detector configurations\n",
    "5. **Reporting**: Generate automated reports for stakeholders\n",
    "\n",
    "### üí° Tips:\n",
    "- Use the command-line script for automated report generation\n",
    "- Customize color schemes and styling for your organization\n",
    "- Combine multiple evaluation runs for comprehensive analysis\n",
    "- Share interactive HTML reports with stakeholders"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}